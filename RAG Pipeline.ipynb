{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe1ec53",
   "metadata": {},
   "source": [
    "# Installing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81180824",
   "metadata": {},
   "source": [
    "!pip install -qU langchain-text-splitters langchain-community langgraph langchain-google-genai langchain-huggingface langchain-chroma glob2 pandas numpy pypdf sentence-transformers scikit-learn pyMuPDF rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "import fitz\n",
    "from google import genai\n",
    "from pathlib import Path\n",
    "from typing_extensions import List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Langchain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import START, StateGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41428e67",
   "metadata": {},
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb83a2",
   "metadata": {},
   "source": [
    "### Gemini & Langsmith API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08b2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdad05",
   "metadata": {},
   "source": [
    "### Chat Model: ***ChatGoogleGenerativeAI***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0deaca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5c3e9",
   "metadata": {},
   "source": [
    "### Embeddings Model: ***BAAI/bge-small-en*** from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_cache_path = \"/content/embeddings_cache\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en\",\n",
    "    cache_folder=embeddings_cache_path,\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d4a73",
   "metadata": {},
   "source": [
    "### Vector Store: Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_db_cache_path = \"/content/chroma_db\"\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings, persist_directory=chroma_db_cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72050d3",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d166e2",
   "metadata": {},
   "source": [
    "### Loading Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder = r\"/content/Web Scraped Solder Bridging\"\n",
    "\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    pdf_paths = list(Path(folder_path).glob(\"*.pdf\"))\n",
    "    print(pdf_paths)\n",
    "    docs = []\n",
    "    for path in pdf_paths:\n",
    "        doc = fitz.open(str(path))\n",
    "        for page_num, page in enumerate(doc):\n",
    "            text = page.get_text().strip()\n",
    "            if text:\n",
    "                docs.append(Document(\n",
    "                    page_content=text,\n",
    "                    metadata={\"source\": path.name, \"page\": page_num + 1}\n",
    "                ))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b73db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_pdfs_from_folder(pdf_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac0b0e",
   "metadata": {},
   "source": [
    "total_chars = sum(len(doc.page_content) for doc in docs)\n",
    "print(f\"Total characters in 6 documents combined: {total_chars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3077d4a2",
   "metadata": {},
   "source": [
    "### Chunking Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_by_page(doc):\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, emit exactly one chunk per page,\n",
    "    safely accessing metadata via .get().\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    source = doc.metadata.get(\"source\", \"unknown\")\n",
    "    page_num = doc.metadata.get(\"page\", 0)\n",
    "\n",
    "    chunks.append(\n",
    "        Document(\n",
    "            page_content=doc.page_content,\n",
    "            metadata={\n",
    "                \"source\": source,\n",
    "                \"page\": page_num,\n",
    "                \"section\": f\"page_{page_num}\",\n",
    "                \"splitter\": \"page\",\n",
    "                \"id\": f\"{source}_p{page_num}_s0\",\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Usage:\n",
    "# page_chunks = chunk_by_page(docs)\n",
    "# for chunk in page_chunks:\n",
    "#     print(chunk.metadata.get('source'), chunk.metadata.get('page'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "for doc in docs:\n",
    "    chunks.extend(chunk_by_page(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451a5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa12758",
   "metadata": {},
   "source": [
    "### Inserting Chunks in Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cd2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Insert Approach\n",
    "batch_size = 10\n",
    "document_ids = []\n",
    "\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch = chunks[i : i + batch_size]\n",
    "    batch_ids = vector_store.add_documents(documents=batch)\n",
    "    document_ids.extend(batch_ids)\n",
    "    print(\n",
    "        f\"Inserted {min(i + batch_size, len(chunks))}/{len(chunks)} chunks\"\n",
    "    )\n",
    "\n",
    "print(\"Done. Example IDs: \", document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3837b",
   "metadata": {},
   "source": [
    "# Retrieval and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9643a69",
   "metadata": {},
   "source": [
    "### Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────  EFFECTS  ──────────────────────────\n",
    "custom_prompt_effects = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=r\"\"\"\n",
    "You are a highly concise assistant.\n",
    "\n",
    "Task → List the **best five effects** (max) of the failure mode in the question, **using ONLY the context**.\n",
    "\n",
    "Constraints\n",
    "1. Each effect = 3-4 words.\n",
    "2. No sentences, no extra text.\n",
    "3. If zero effects are supported, answer exactly:\n",
    "   {{\"process\":\"\", \"failure_mode\":\"\", \"effects\":[]}}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Respond **only** in this JSON schema:\n",
    "{{\n",
    "  \"process\": \"<process name from question>\",\n",
    "  \"failure_mode\": \"<failure mode from question>\",\n",
    "  \"effects\": [\"effect 1\", \"effect 2\", \"effect 3\", \"effect 4\", \"effect 5\"]\n",
    "}}\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b37cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────  CAUSES  ───────────────────────────\n",
    "custom_prompt_causes = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=r\"\"\"\n",
    "You are a highly concise assistant.\n",
    "\n",
    "Task → List the **best five causes** (max) of the failure mode in the question, **using ONLY the context**.\n",
    "\n",
    "Constraints\n",
    "1. Each cause = 3-4 words.\n",
    "2. No sentences, no extra text.\n",
    "3. If zero causes are supported, answer exactly:\n",
    "   {{\"process\":\"\", \"failure_mode\":\"\", \"causes\":[]}}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Respond **only** in this JSON schema:\n",
    "{{\n",
    "  \"process\": \"<process name from question>\",\n",
    "  \"failure_mode\": \"<failure mode from question>\",\n",
    "  \"causes\": [\"cause 1\", \"cause 2\", \"cause 3\", \"cause 4\", \"cause 5\"]\n",
    "}}\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc73db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────  ACTIONS / REMEDIES  ─────────────────────\n",
    "custom_prompt_actions = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=r\"\"\"\n",
    "You are a highly concise assistant.\n",
    "\n",
    "Task → Suggest the **best five corrective actions / remedies** (max) that mitigate or fix the failure mode mentioned in the question, **using ONLY the context**.\n",
    "\n",
    "Constraints\n",
    "1. Each action = 3-4 words.\n",
    "2. No sentences, no extra text.\n",
    "3. If zero actionable fixes are supported, answer exactly:\n",
    "   {{\"process\":\"\", \"failure_mode\":\"\", \"actions\":[]}}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Respond **only** in this JSON schema:\n",
    "{{\n",
    "  \"process\": \"<process name from question>\",\n",
    "  \"failure_mode\": \"<failure mode from question>\",\n",
    "  \"actions\": [\"action 1\", \"action 2\", \"action 3\", \"action 4\", \"action 5\"]\n",
    "}}\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aebc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(smart_chunks)\n",
    "bm25_retriever.k = 5\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_store.as_retriever(search_kwargs={\"k\": 5})],\n",
    "    weights=[0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2debdbe",
   "metadata": {},
   "source": [
    "### Langchain Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027bb03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search(BaseModel):\n",
    "    query: str = Field(description=\"Search query to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506e2553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3537c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = ensemble_retriever.invoke(query.query)[:8]\n",
    "    print(\"No. of docs retrieved:\", len(retrieved_docs))\n",
    "    \n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_effects(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"]).strip()\n",
    "    prompt_input = custom_prompt_effects.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content\n",
    "    })\n",
    "    response = llm.invoke(prompt_input)\n",
    "\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c643a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causes(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"]).strip()\n",
    "    prompt_input = custom_prompt_causes.invoke({\n",
    "        \"question\": state[\"question\"],\n",
    "        \"context\": docs_content\n",
    "    })\n",
    "    response = llm.invoke(prompt_input)\n",
    "\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_actions(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"]).strip()\n",
    "    prompt_input = custom_prompt_actions.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": docs_content}\n",
    "    )\n",
    "    response = llm.invoke(prompt_input)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- EFFECTS ----------------\n",
    "effects_graph_builder = StateGraph(State).add_sequence([\n",
    "    analyze_query,\n",
    "    retrieve,\n",
    "    generate_effects\n",
    "])\n",
    "effects_graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph_effects = effects_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CAUSES -----------------\n",
    "causes_graph_builder = StateGraph(State).add_sequence([\n",
    "    analyze_query,\n",
    "    retrieve,\n",
    "    generate_causes\n",
    "])\n",
    "causes_graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph_causes = causes_graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- ACTIONS / REMEDIES ----- \n",
    "actions_graph_builder = StateGraph(State).add_sequence([\n",
    "    analyze_query,\n",
    "    retrieve,\n",
    "    generate_actions\n",
    "])\n",
    "actions_graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph_actions = actions_graph_builder.compile()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09971b6",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e72cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Recommeded Action generation\n",
    "question = \"What is the solution for NWO/HIP ?\"\n",
    "response = graph_actions.invoke({\"question\": question})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ae2fc",
   "metadata": {},
   "source": [
    "print(response[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2000fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test EFFECTS generation\n",
    "question = \"What are the potential effects of SOLDER BEADING ?\"\n",
    "response = graph_effects.invoke({\"question\": question})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d60dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test CAUSES generation\n",
    "question = \"What are the effects of Overheated joints?\"\n",
    "response = graph_causes.invoke({\"question\": question})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ab3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636bea8",
   "metadata": {},
   "source": [
    "# Populating the FMEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3198462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_invoke(graph, question, retries=2, wait=60):\n",
    "    \"\"\"Safely invokes a graph with retry logic.\"\"\"\n",
    "    try:\n",
    "        return graph.invoke({\"question\": question})\n",
    "    except Exception as e:\n",
    "        if retries > 0:\n",
    "            print(f\"Retrying after error: {e}\")\n",
    "            time.sleep(wait)\n",
    "            return safe_invoke(graph, question, retries - 1, wait)\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55264bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(response_text):\n",
    "    \"\"\"Cleans and parses JSON safely from model output.\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group())\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON parsing failed: {e}\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context_attributes(context_list):\n",
    "    \"\"\"Formats the document source and page attributes for traceability.\"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f'Doc {i}: {{page: {doc.metadata.get(\"page\")}, doc: {doc.metadata.get(\"source\")}}}'\n",
    "            for i, doc in enumerate(context_list)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_update(row, effects, causes):\n",
    "    print(\"x\" + \"-\" * 64 + \"x\")\n",
    "    print(f\"SMT Process: {row['SMT Process']}\")\n",
    "    print(f\"Failure Mode: {row['Failure Mode']}\")\n",
    "    print(\"Effects:\" if effects else \"No effects retrieved.\")\n",
    "    if effects:\n",
    "        print(effects)\n",
    "    print(\"Causes:\" if causes else \"No causes retrieved.\")\n",
    "    if causes:\n",
    "        print(causes)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d9332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_effects_and_causes(\n",
    "    df, graph_effects, graph_causes, graph_actions, sleep_between=6\n",
    "):\n",
    "    for index, row in df.iterrows():\n",
    "        process = row[\"SMT Process\"]\n",
    "        failure_mode = row[\"Failure Mode\"]\n",
    "\n",
    "        # EFFECTS\n",
    "        question_effects = f\"What are the effects of {failure_mode} ?\"\n",
    "        result_effects = safe_invoke(graph_effects, question_effects)\n",
    "\n",
    "        if result_effects[\"context\"]:\n",
    "            parsed_effects = parse_json_response(result_effects[\"answer\"])\n",
    "            effects_list = parsed_effects.get(\"effects\", [])\n",
    "            df.at[index, \"Potential Effects\"] = \", \".join(effects_list)\n",
    "            df.at[index, \"Effects_Attr\"] = format_context_attributes(\n",
    "                result_effects[\"context\"]\n",
    "            )\n",
    "        else:\n",
    "            df.at[index, \"Potential Effects\"] = \"\"\n",
    "            df.at[index, \"Effects_Attr\"] = \"\"\n",
    "\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "        # CAUSES\n",
    "        question_causes = f\"What are the causes of {failure_mode} ?\"\n",
    "        result_causes = safe_invoke(graph_causes, question_causes)\n",
    "\n",
    "        if result_causes[\"context\"]:\n",
    "            parsed_causes = parse_json_response(result_causes[\"answer\"])\n",
    "            causes_list = parsed_causes.get(\"causes\", [])\n",
    "            df.at[index, \"Potential Causes\"] = \", \".join(causes_list)\n",
    "            df.at[index, \"Causes_Attr\"] = format_context_attributes(\n",
    "                result_causes[\"context\"]\n",
    "            )\n",
    "        else:\n",
    "            df.at[index, \"Potential Causes\"] = \"\"\n",
    "            df.at[index, \"Causes_Attr\"] = \"\"\n",
    "\n",
    "        # Recommended Actions\n",
    "        q_actions = f\"What are the recommended actions for {failure_mode} ?\"\n",
    "        r_actions = safe_invoke(graph_actions, q_actions)\n",
    "\n",
    "        if r_actions[\"context\"]:\n",
    "            actions_json = parse_json_response(r_actions[\"answer\"])\n",
    "            actions_list = actions_json.get(\"actions\", [])\n",
    "            df.at[index, \"Recommended Actions\"] = \", \".join(actions_list)\n",
    "            df.at[index, \"Recommended_Actions_Attr\"] = format_context_attributes(\n",
    "                r_actions[\"context\"]\n",
    "            )\n",
    "        else:\n",
    "            df.at[index, \"Recommended Actions\"] = \"\"\n",
    "            df.at[index, \"Recommended_Actions_Attr\"] = \"\"\n",
    "\n",
    "        # Optional logging\n",
    "        log_update(\n",
    "            row, df.at[index, \"Potential Effects\"], df.at[index, \"Potential Causes\"]\n",
    "        )\n",
    "\n",
    "        time.sleep(sleep_between)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmea_df = pd.read_csv(\"/content/FMEA_with_Processes_and_FMs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = fill_effects_and_causes(fmea_df, graph_effects, graph_causes, graph_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_csv(\"Final Generated FMEA.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
